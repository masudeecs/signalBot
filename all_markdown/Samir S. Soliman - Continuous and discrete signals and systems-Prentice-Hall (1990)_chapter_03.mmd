## Chapter 3 Fourier Series

### 3.1 Introduction

In Section 1.7, we saw that any arbitrary signal can be represented over a finite interval as an infinite series in terms of some set of orthogonal basis functions. This representation is more universal than a Taylor series in the sense that it permits an arbitrary signal, not necessary analytic, to be represented in this form. In this chapter, we investigate a method for expressing periodic signals in terms of harmonically related complex exponentials. The choice of complex exponentials as an orthogonal basis is appropriate since the complex exponentials are periodic, relatively easy to manipulate mathematically, and the result has meaningful physical interpretation.

The representation of an arbitrary periodic signal in terms of simple basic functions, such as complex exponentials, is a matter of great practical importance. Such a representation leads to the Fourier series that are used extensively in all fields of science and engineering. The Fourier series is named after French physicist Jean Baptiste Fourier (1768\(-\)1830), who was the first to suggest that periodic signals could be represented by a sum of sinusoids. Using such a representation along with the superposition property of linear systems provides a means of solving for the response of linear systems to arbitrary periodic signals.

So far, we have only considered time-domain descriptions of continuous-time signals and systems. In this chapter, we introduce the concept of frequency-domain representations. We see how to decompose periodic signals into their frequency components. These results can be extended to nonperiodic signals, as will be shown in Chapter 4.

Periodic signals occur in a wide range of physical phenomena, a few examples of which are acoustic and electromagnetic waves of most types, vertical displacement of a mechanical pendulum, the periodic vibrations of musical instruments, and the beautiful patterns of crystal structures.

In the present chapter, we discuss basic concepts, facts, and techniques in connection with Fourier series. Illustrative examples and some important engineering applications are included. We begin by considering periodic signals in Section 3.2 and develop procedures for resolving such signals into a linear combination of complex exponential functions. In Section 3.3, we discuss the sufficient conditions for a periodic signal to be represented in terms of a Fourier series. These conditions are known as the Dirichlet conditions. Fortunately, all the periodic signals (phenomena) that we deal with in practice obey these conditions. As with any other mathematical tool, Fourier series possess several useful properties. These properties are developed in Section 3.4. Understanding such properties helps us move easily from the time domain to the frequency domain and vice versa. In Section 3.5, we use the properties of the Fourier series to find the response of LTI systems to periodic signals. The effects of truncating the Fourier series and the Gibbs phenomenon are discussed in Section 3.6. We will see that whenever we attempt to reconstruct a discontinuous signal from its Fourier series, we encounter a strange behavior in the form of signal overshoot at the points of discontinuities. This overshoot effect does not go away even when we increase the number of terms used in reconstructing the signal.

### 3.2 The Exponential Fourier Series

Recall from Chapter 1 that a signal is periodic if for some positive nonzero value of,

(3.2.1)

The quantity for which Equation (3.2.1) is satisfied is referred to as the fundamental period, whereas referred to as the fundamental radian frequency and is denoted by. The graph of a periodic signal is obtained by periodic repetition of its graph in any interval of length, as shown in Figure 3.2.1. From Equation (3.2.1), it follows that, are also periods of. As was demonstrated in Chapter 1, if two signals, and, are periodic with period, then

(3.2.2)

is also periodic with period.

Figure 3.2.1: Periodic signal.

Familiar examples of periodic signals are the sine, cosine, and complex exponential functions. Note that a constant signal \(x\left(t\right)=c\) is also a periodic signal in the sense of the definition because Equation (3.2.1) is satisfied for every positive \(T\).

In this section, we consider the representation of periodic signals by an orthogonal set of basis functions. We saw in Section 1.7 that the set of complex exponentials \(\phi_{n}(t)=\exp\left[\,j2n\pi t/T\,\right]\) forms an orthogonal set. If we select such a set as basis functions, then according to Equation (1.7.3)

\[x(t)=\sum_{n\ =\ -\infty}^{\infty}c_{n}\,\exp\left[\ j\frac{2n\pi t}{T}\ \right] \tag{3.2.3}\]

where, from Equation (1.7.4), \(c_{n}\) are complex constants and are given by

\[c_{n}=\frac{1}{T}\int_{0}^{T}x\left(t\right)\exp\left[\ -j\frac{2n\pi t}{T}\ \right]\,dt \tag{3.2.4}\]

Each term of the series has a period \(T\) and fundamental radian frequency \(2\pi/T=\omega_{0}\). Hence, if the series converges, its sum is periodic with period \(T\). Such a series is called the complex exponential Fourier series and the \(c_{n}\) are called the Fourier coefficients. Note that because of the periodicity of the integrand, the interval of integration in the previous equation can be replaced by any other interval of length \(T\), for instance, by the interval \(t_{0}\leq t\leq t_{0}+T\), where \(t_{0}\) is arbitrary. We denote integration over an interval of length \(T\) by the symbol \(\int_{<T>}\). We observe that even though an infinite number of frequencies are used to synthesize the original signal in the Fourier-series expansion, they do not constitute a continuum; each frequency term is a multiple of \(\omega_{0}/2\pi\). The frequency corresponding to \(n=1\) is called the fundamental, or first harmonic; \(n=2\), corresponds to the second harmonic, and so on. Coefficients \(c_{n}\) define a complex-valued function of the discrete frequencies \(n\omega_{0}\), where \(n=0\), \(\pm 1\), \(\pm 2\), \(\ldots\). The dc component, or the full-cycle time average, of \(x\left(t\right)\) is equal to \(c_{0}\) and is obtained by setting \(n=0\) in Equation (3.2.4). Calculated values of \(c_{0}\) can be checked by inspecting \(x\left(t\right)\), a recommended practice to test the validity of the result obtained by integration. The plot of \(\left|\,c_{n}\,\right|\) versus \(n\omega_{0}\) displays the amplitudes of the various frequency components comprising \(x\left(t\right)\). Such a plot is, therefore, called the amplitude, or magnitude spectrum, of periodic signal \(x\left(t\right)\). The locus of the tips of the magnitude lines is called the envelope of the magnitude spectrum. Similarly, the phase of the sinusoidal components comprising \(x\left(t\right)\) is equal to \(\times\)\(c_{n}\) and the plot of \(\times\)\(c_{n}\) versus \(n\omega_{0}\) is called the phase spectrum of \(x\left(t\right)\). In summary, the amplitude and phase spectra of any given periodic signal are defined in terms of the magnitude and phase of \(c_{n}\). Since the spectra consist of a set of lines representing the magnitude and phase at \(\omega=n\omega_{0}\), these spectra are referred to as line spectra.

For real-valued signals (noncomplex), the complex conjugate of \(c_{n}\) is given by

\[c_{n}^{*}=\left[\frac{1}{T}\int_{<T>}x\left(t\right)\exp\left[\ \frac{-j\,2n\pi t}{T}\ \right]\,dt\right]^{*}\]\[=\frac{1}{T}\int\limits_{<T>}x\left(t\right)\,\exp\left[\,\,\frac{-j2(-n)\pi t}{T} \,\right]\,dt\] \[=c_{-n} \tag{3.2.5}\]

Hence,

\[\left|c_{-n}\right|=\left|c_{n}\right|\quad\text{ and }\quad\nless c_{-n}=- \nless c_{n} \tag{3.2.6}\]

which means that the amplitude spectrum has even symmetry and the phase spectrum has odd symmetry. This property for real-valued signals allows us to regroup the exponential series into complex-conjugate pairs, except for \(c_{0}\), as follows:

\[x\left(t\right) =c_{0}+\sum\limits_{m=-\infty}^{-1}c_{m}\,\exp\left[\,\frac{j2m \pi t}{T}\,\right]+\sum\limits_{m=1}^{\infty}c_{m}\,\exp\left[\,\frac{j2m\pi t }{T}\,\right]\] \[=c_{0}+\sum\limits_{n=1}^{\infty}c_{-n}\,\exp\left[\,\frac{-j2n \pi t}{T}\,\right]+\sum\limits_{n=1}^{\infty}c_{n}\,\exp\left[\,\frac{j2n\pi t }{T}\,\right]\] \[=c_{0}+\sum\limits_{n=1}^{\infty}\left(c_{-n}\,\exp\left[\,\frac{ -j2n\pi t}{T}\,\right]+c_{n}\,\exp\left[\,\frac{j2n\pi t}{T}\,\right]\right)\] \[=c_{0}+\sum\limits_{n=1}^{\infty}2\,\Re\left\{c_{n}\,\exp\left[\, \frac{j2n\pi t}{T}\,\right]\right\}\] \[=c_{0}+\sum\limits_{n=1}^{\infty}\left(2\,\Re\left\{c_{n}\,\right\} \,\cos\,\frac{2n\pi t}{T}-2\,\Im\left\{c_{n}\right\}\,\sin\,\frac{2n\pi t}{T}\right) \tag{3.2.7}\]

where \(\Re\left\{\,\cdot\,\right\}\) and \(\Im\left\{\,\cdot\,\right\}\) denote the real and imaginary parts of the arguments, respectively. Equation (3.2.7) can be written as

\[x\left(t\right)=a_{0}+\sum\limits_{n=1}^{\infty}a_{n}\,\cos\frac{2n\pi t}{T} +b_{n}\sin\frac{2n\pi t}{T} \tag{3.2.8}\]

The expression for \(x\left(t\right)\) in Equation (3.2.8) is called the trigonometric Fourier series for periodic signal \(x\left(t\right)\). Coefficients \(a_{n}\) and \(b_{n}\) are given by

\[a_{0} =c_{0}=\frac{1}{T}\int\limits_{<T>}x\left(t\right)\,dt \tag{3.2.9a}\] \[a_{n} =2\Re\left\{c_{n}\right\}=\frac{2}{T}\int\limits_{<T>}x\left(t \right)\cos\frac{2n\pi t}{T}\,\,dt\] (3.2.9b) \[b_{n} =-2\Im\left\{c_{n}\right\}=\frac{2}{T}\int\limits_{<T>}x\left(t \right)\,\sin\,\frac{2n\pi t}{T}\,\,dt \tag{3.2.9c}\]

In terms of the magnitude and phase of \(c_{n}\), the real-valued signal \(x\left(t\right)\) can be expressed as

\[x\left(t\right) =c_{0}+\sum\limits_{n=1}^{\infty}2\left|c_{n}\right|\,\cos\left( \frac{2n\pi t}{T}+\nless c_{n}\right)\] \[=c_{0}+\sum\limits_{n=1}^{\infty}A_{n}\,\cos\left(\frac{2n\pi t}{ T}+\phi_{n}\right) \tag{3.2.10}\]where

\[A_{n}=2\ |\ c_{n}\ | \tag{3.2.11}\]

and

\[\phi_{n}=\ \preccurlyeq c_{n} \tag{3.2.12}\]

Equation (3.2.10) represents an alternative form of the Fourier series that is more compact and meaningful than Equation (3.2.8). Each term in the series represents an oscillator needed to generate the periodic signal \(x(t)\).

A display of \(|\ c_{n}|\) and \(\preccurlyeq c_{n}\) versus \(n\) or \(n\omega_{0}\) for both positive and negative values of \(n\) is called a two-sided amplitude spectrum. The display of \(A_{n}\) and \(\phi_{n}\) versus positive \(n\) or \(n\omega_{0}\) is called a one-sided spectrum. The two-sided spectra are encountered most often in theoretical treatments because of the convenient nature of the complex Fourier series. It must be emphasized that the existence of a line at a negative frequency does not imply that the signal is made of negative frequency components, since for every component \(c_{n}\exp\left[\left.j\,2n\pi t/T\right]\right\), there is an associated one of the form \(c_{-n}\ \exp\left[\left.-j\,2n\pi t/T\right]\right.\)These complex signals combine to create the real component \(a_{n}\cos\left(2n\pi t/T\right)+b_{n}\sin\left(2n\pi t/T\right)\). Note also that from the definition of a definite integral, it follows that if \(x(t)\) is continuous or merely piecewise continuous (continuous except for finitely many jumps in the interval of integration), the Fourier coefficients exist and we can compute them by the indicated integrals.

Let us illustrate the practical use of the previous equations by the following examples. We will see numerous other examples in the following sections.

**Example 3.2.1**: We want to find the line spectra for the periodic signal shown in Figure 3.2.2. Signal \(x(t)\) has the following analytic representation

**Figure 3.2.2**: Signal \(x(t)\) for Example 3.2.1.

\[x(t)=\begin{cases}-K,&-1<t<0\\ K,&0<t<1\end{cases}\]

and \(x(t+2)=x(t)\). Therefore, \(\omega_{0}=2\pi/2=\pi\). Signals of this type can occur as external forces acting on mechanical systems, electromotive forces in electric circuits, etc. The Fourier coefficients are

\[c_{n} =\frac{1}{2}\int\limits_{-1}^{1}x(t)\,\exp\left[-jn\pi t\right]\,dt\] \[=\frac{1}{2}\left[\int\limits_{-1}^{0}-K\,\exp\left[-jn\pi t \right]\,dt+\int\limits_{0}^{1}K\,\exp\left[-jn\pi t\right]\,dt\right]\] \[=\frac{K}{2}\left(\frac{1-\exp\left[jn\pi\right]}{jn\pi}+\frac{ \exp\left[-jn\pi\right]-1}{-jn\pi}\right)\] \[=\frac{K}{jn\pi}\left\{1-\frac{1}{2}\left(\exp\left[jn\pi\right]+ \exp\left[-jn\pi\right]\right)\right\} \tag{3.2.13}\] \[=\begin{cases}\frac{2K}{jn\pi},&n\,\text{ odd}\\ 0,&n\,\text{ even}\end{cases} \tag{3.2.14}\]

The amplitude spectrum is

\[\left|c_{n}\right|=\begin{cases}\frac{2K}{\left|n\right|\pi},&n\,\text{ odd}\\ 0,&n\,\text{ even}\end{cases}\]

The dc component or the average value of the periodic signal \(x(t)\) is obtained by setting \(n=0\). When we substitute \(n=0\) in Equation (3.2.13), we obtain an undefined result. This can be circumvented by using L'Hopital's rule, with the result \(c_{0}=0\). This result can be checked by noticing that \(x(t)\) is an odd function and the area under the curve represented by \(x(t)\) over one period of the signal is zero.

The phase spectrum of \(x(t)\) is given by

\[\times c_{n}=\begin{cases}-\frac{\pi}{2},&n=(2m-1),\,\,\,m=1,\,2,\,\ldots\\ 0,&n=2m,\,\,\,m=0,\,1,\,2\,\ldots\\ \frac{\pi}{2},&n=-\,(2m-1),\,\,\,m=1,\,2,\,\ldots\end{cases}\]

The line spectra of \(x(t)\) are displayed in Figure 3.2.3. Note that the amplitude spectrum has even symmetry and that the phase spectrum has odd symmetry.

**Example 3.2.2**: A sinusoidal voltage \(E\) sin \(\omega_{0}\,t\) is passed through a half-wave rectifier that clips the negative portion of the waveform, as shown in Figure 3.2.4. Such signals may be encountered in rectifier design problems. Rectifiers are circuits that produce dc (direct current) from ac (alternating current).

The analytic representation of \(x(t)\) is

\[x\left(t\right)=\begin{cases}0,&\text{when}\quad\frac{-\pi\,t}{\omega_{0}}<t<0\\ E\,\sin\omega_{0}t,&\text{when}\quad 0<t<\frac{\pi\,t}{\omega_{0}}\end{cases}\]

Figure 3.2.3: Line spectra for the periodic signal \(x\left(t\right)\) of Example 3.2.1 (a) Magnitude spectrum and (b) phase spectrum.

Figure 3.2.4: Signal \(x\left(t\right)\) for Example 3.2.2.

and \(x(t+2\pi/\omega_{0})=x(t)\). Since \(x(t)=0\) when \(-\pi/\omega_{0}<t<0\), we obtain from Equation (3.2.4),

\[\begin{split} c_{n}&=\frac{1}{T}\int\limits_{0}^{T}E \,\sin\omega_{0}t\,\exp\left[\,-j\frac{2n\pi}{T}\,\,\right]\,dt\\ &=\frac{E\omega_{0}}{2\pi}\int\limits_{0}^{\pi/\omega_{0}}\frac{ 1}{2j}\left[\exp\left[\,j\omega_{0}\,t\,\,\right]-\exp\left[\,-j\omega_{0}\,t \,\,\right]\right]\exp\left[\,-jn\omega_{0}\,t\,\,\right]\,dt\\ &=\frac{E\omega_{0}}{4\pi j}\int\limits_{0}^{\pi/\omega_{0}} \left[\exp\left[\,-j\omega_{0}(n-1)t\,\,\right]-\exp\left[\,-j\omega_{0}(n+1) t\right]dt\right.\\ &=\frac{E\,\exp\left[\,-jn\pi/2\,\,\right]}{2\pi(1-n^{2})}\left( \exp\left[\,\frac{-jn\pi}{2}\,\,\right]+\exp\left[\,\frac{jn\pi}{2}\,\,\right] \right)\\ &=\frac{E}{\pi(1-n^{2})}\,\cos\left(n\,\pi/2\right)\exp\left[\,- jn\pi/2\,\,\right],\qquad n\neq\pm\,1\\ &=\begin{cases}\frac{E}{\pi(1-n^{2})},&n\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,n\,\,\,\,\text{even}\\ 0,&n\,\,\,\,\text{odd},\,\,\,\,\,\,\,n\neq\pm\,1\end{cases}\end{split} \tag{3.2.15}\]

Setting \(n=0\), we obtain the dc component or the average value of the periodic signal as \(c_{0}=E/\pi\). The result can be verified by calculating the area under one half cycle of a sine wave and dividing by \(T\). To determine coefficients \(c_{1}\) and \(c_{-1}\) that correspond to the first harmonic, we note that we cannot substitute \(n=\pm\,1\) in Equation (3.2.15), since this yields an undetermined quantity. We use Equation (3.2.4) instead with \(n=\pm\,1\) which results in

\[c_{1}=\frac{E}{4j}\quad\text{and}\quad c_{-1}=\frac{-E}{4j}\]

The line spectra of \(x(t)\) are displayed in Figure 3.2.5.

In general, a rectifier is used to convert an ac signal to a dc signal. Ideally, rectified output \(x(t)\) should consist only of a dc component. Any ac component contributes to the ripple (deviation from pure dc) in the signal. As can be seen from Figure 3.2.5, the amplitudes of the harmonics decrease rapidly as \(n\) increases, so that the main contribution to the ripple comes from the first harmonic. The ratio of the amplitudes of the first harmonic to the dc component can be used as a measure of the amount of the ripple in the rectified signal. In this example, this ratio is equal to \(\pi/4\). More complex circuits can be used to produce less ripple content (see Example 3.5.4).

**Example**: **3.2.3**: Consider the square-wave signal shown in Figure 3.2.6. The analytic representation of \(x(t)\) is \[x(t)=\begin{cases}0,&\text{when}\ \ \frac{-T}{2}<t<\ \frac{-\tau}{2}\\ K,&\text{when}\ \ \frac{-\tau}{2}<t<\ \frac{\tau}{2}\\ 0,&\text{when}\ \ \frac{\tau}{2}<t<\ \frac{T}{2}\end{cases}\]and \(x(t+T)=x(t)\). Signals of this type can be produced by pulse generators and are used extensively in radar and sonar systems. From Equation (3.2.4), we obtain

\[c_{n} =\frac{1}{T}\int\limits_{-T/2}^{T/2}x(t)\,\exp\left[\frac{-j2n\pi t }{T}\ \right]\,dt=\frac{1}{T}\int\limits_{-\tau/2}^{\tau/2}K\,\exp\left[\frac{-j2n \pi t}{T}\ \right]\,dt\] \[=\frac{K}{j2n\pi}\,\left[\,\exp\left[\ \frac{jn\pi\tau}{T}\ \right]-\exp\left[\frac{-jn\pi\tau}{T}\ \right]\right]\] \[. \tag{3.2.17}\]

where \(\,\mathrm{sinc}\left(\lambda\right)=\sin\left(\pi\lambda\right)/\pi\lambda\). The \(\,\mathrm{sinc}\) function plays an important role in Fourier analysis and in the study of LTI systems. This function has a maximum value at \(\lambda=0\) and approaches zero as \(\lambda\) approaches infinity, oscillating through positive and negative values. It goes through zero at \(\lambda=\pm\ 1,\ \pm\,2,\ldots\).

Let us investigate the effect of changing \(T\) on the frequency spectrum of \(x\left(t\right)\). For fixed \(\tau\), increasing \(T\) reduces the amplitude of each harmonic as well as the fundamental frequency and, hence, the spacing between harmonics. However, the shape of the spectrum is dependent only on the pulse shape and does not change as \(T\) increases except for the amplitude factor. A convenient measure of the frequency spread (known as the bandwidth) is the distance from the origin to the first zero crossing of the \(\,\mathrm{sinc}\) function. This distance is equal to \(2\pi/\tau\) and is independent of \(T\). Other measures of the frequency width of the spectrum are discussed in detail in Section 4.5.

We conclude that as the period increases, the amplitude becomes smaller and the spectrum becomes denser, whereas the shape of the spectrum remains the same and does not depend on the repetition period \(T\). The amplitude spectra of \(x\left(t\right)\) with \(\tau=1\) and \(T=5\), \(10\), and \(15\) are displayed in Figure 3.2.7.

In this example, we show that \(x\left(t\right)=t^{2}\), \(-\pi<t<\pi\), with \(x\left(t+2\pi\right)=x\left(t\right)\) has the following Fourier series representation:

\[x\left(t\right)=\frac{\pi^{2}}{3}-4(\cos t-\frac{1}{4}\cos 2t+\frac{1}{9} \cos 3t-\ldots\ ) \tag{3.2.18}\]

Note that \(x\left(t\right)\) is periodic with period \(2\pi\) and fundamental frequency \(\omega_{0}=1\). The complex Fourier series coefficients are

\[c_{n}=\frac{1}{2\pi}\int\limits_{-\pi}^{\pi}t^{2}\,\exp\left[\,-jnt\,\right]\,dt\]

Integrating by parts twice yields

\[c_{n}=\frac{2\cos n\pi}{n^{2}},\qquad n\neq 0\]The term \(c_{0}\) is obtained from

\[c_{0} =\frac{1}{2\pi}\int\limits_{-\pi}^{\pi}t^{2}\ dt\] \[=\frac{\pi^{2}}{3}\]

From Equations (3.2.9b) and (3.2.9c),

\[a_{n} =2\ \text{Re}\left\{c_{n}\right\}=\frac{4}{n^{2}}\ \cos n\pi\] \[b_{n} =-2\ \text{Im}\left\{c_{n}\right\}=0\]

because \(c_{n}\) is real. Substituting in Equation (3.2.8), we obtain Equation (3.2.18).

Figure 3.2.7: Line spectra for the \(x\)(\(t\)) in Example 3.2.3. (a) Magnitude spectrum for \(\tau=1\) and \(T=5\), (b) Magnitude spectrum for \(\tau=1\) and \(T=10\), (c) and Magnitude spectrum for \(\tau=1\) and \(T=15\).

**Example 3.2.5**: Consider

\[x(t)=1+2\sin\pi t+\cos\pi t-\sin(2\pi t-\frac{\pi}{6})-2\cos(2\pi t+\frac{\pi}{3})\]

We want to write \(x(t)\) as

\[x(t)=\sum_{n\ =\ -\infty}^{\infty}c_{n}\ \exp\left[jn\omega_{0}t\right]\]

One approach to find \(c_{n}\) is to apply Equation (3.2.4). For this simple example, however, it is easier to expand the sine and cosine signals in terms of complex exponentials and identify by inspection the Fourier- series coefficients. That is,

\[x(t) =1+\frac{1}{j}\left[\exp\left[j\pi t\right]-\ \exp\left[-j\pi t \right]\right]+\frac{1}{2}\left[\exp\left[j\pi t\right]+\ \exp\left[-j\pi t\right]\right]\] \[-\ \frac{1}{2j}\left[\exp\left[j(2\pi t-\frac{\pi}{6})\right]- \exp\left[-j(2\pi t-\frac{\pi}{6})\right]\right]\] \[-\ \left[\exp\left[j(2\pi t+\frac{\pi}{3})\right]+\exp\left[-j(2\pi t +\frac{\pi}{3})\right]\right]\]

Collecting terms, we obtain

\[x(t) =1+(\frac{1}{2}-j)\ \exp\left[\ j\pi t\right]+(\frac{1}{2}+j)\ \exp\left[-j\pi t\right]\] \[-(\frac{1}{4}+\frac{\sqrt{3}}{4}\ j)\ \exp\left[\ j\ 2\pi t \right]-(\frac{1}{4}-\frac{\sqrt{3}}{4}\ j)\exp\left[-j\ 2\pi t\right]\]

Comparing with the given expression for the Fourier series, we conclude that \(\omega_{0}=\pi\), and the Fourier series coefficients are

\[c_{0} =1\] \[c_{1} =c_{-1}^{*} =\frac{1}{2}-j\] \[c_{2} =c_{-2}^{*} =-(\frac{1}{4}+\frac{\sqrt{3}}{4}\ j)\]

and

\[c_{n}=0\,\qquad n>2\]

The signal \(x(t)\) is called a band-limited signal since its amplitude spectrum contains only a finite number (5) of lines.

### 3.3 Dirichlet Conditions

The work of Fourier in representing a periodic signal as a trigonometric series is a remarkable result. His results indicate that a periodic signal, such as the signal with discontinuities in Figure 3.2.2, can be expressed as a sum of sinusoids. Since sinusoids are infinitely smooth signals (i.e., they have ordinary derivatives of arbitrary high order), it is difficult to believe that these discontinuous signals can be expressed as a

conditions, the series converges, and \(x(t)\) is equal to the sum of the infinite series. Setting \(t=1/2\) in Equation (3.3.2), we obtain

\[x(\frac{1}{2})=K=\frac{4\dot{K}}{\pi}(1-\frac{1}{3}+\frac{1}{5}+\ \cdots\ \ (-1)^{n-1}\ \ \frac{1}{2n-1}+\ \cdots\ \ )\]

or

\[\sum_{n=1}^{\infty}(-1)^{n-1}\ \ \frac{1}{2n-1}=\frac{\pi}{4}\]

Consider the periodic signal in Example 3.2.3 with \(\tau=1\) and \(T=2\). The trigonometric Fourier-series coefficients are given by

\[a_{n}=2\ \mathrm{Re}\left\{c_{n}\right\}=K\ \mathrm{sinc}\ \frac{n}{2}\] \[b_{n}=2\ \mathrm{Im}\left\{c_{n}\right\}=0\]

Thus \(a_{0}=K/2\), and \(a_{n}=0\) when \(n\) is even, \(a_{n}=2K/n\pi\) when \(n=1\), \(5\), \(9\), \(.\.\.\,\) and \(a_{n}=-2K/n\pi\) when \(n=3\), \(7\), \(11\), \(.\.\.\,\) and \(b_{n}=0\) for \(n=\)1,2, \(.\.\.\) Hence, \(x(t)\) can be written as

\[x(t)=\frac{K}{2}+\frac{2K}{\pi}\left[\cos\pi t-\frac{1}{3}\cos 3\pi t+\frac{1} {5}\cos 5\pi t+\ \cdots\ \ \right] \tag{3.3.3}\]

Since \(x(t)\) satisfies Dirichlet conditions, the sum in Equation (3.3.3) converges at all points except at \(t=\tau=1\), the point of discontinuity of \(x(t)\). The sum in Equation (3.3.3) at the point of discontinuity has the value \(K/2\), which is equal to the arithmetic mean of the values \(K\) and zero of our signal \(x(t)\).

Consider the periodic signal \(x(t)\) in Example 3.2.4. The trigonometric Fourier-series coefficients are

\[a_{0}=\frac{\pi^{2}}{3}\] \[a_{n}=\frac{4}{n^{2}}\ \cos n\pi,\qquad n\neq 0\] \[b_{n}=0\]

Hence, \(x(t)\) can be written as

\[x(t)=\frac{\pi^{2}}{3}+4\sum_{n=1}^{\infty}\frac{(-1)^{n}}{n^{2}}\ \cos nt.sp+2p \tag{3.3.4}\]

Since \(x(t)\) satisfies Dirichlet conditions, then the sum in Equation (3.3.4) converges at all points (\(x\left(t\right)\) is continuous at all \(t\)). At \(t=\pi\), the value of \(x\left(t\right)\) is \(\pi^{2}\), thus,

\[x\left(\pi\right)=\pi^{2}=\frac{\pi^{2}}{3}+4\sum_{n=1}^{\infty}\frac{1}{n^{2}}\]

or

\[\sum_{n=1}^{\infty}\frac{1}{n^{2}}=\frac{\pi^{2}}{6}\]

It is important to realize that the Fourier-series representation of a periodic signal \(x\left(t\right)\) cannot be differentiated term by term to give the representation of \(dx\left(t\right)/dt\). To demonstrate this fact, consider the signal in Example 3.2.3. The derivative of this signal in one period is a pair of oppositely directed \(\delta\)-functions. These are not obtainable by direct differentiation of the Fourier-series representation of \(x\left(t\right)\). However, a Fourier series can be integrated term by term to yield a valid representation of \(\int_{x}\left(t\right)\,dt\).

### Properties of Fourier Series

In this section, we consider a number of properties of the Fourier series. These properties provide us with a better understanding of the notion of the frequency spectrum of a continuous-time signal. In addition, many of these properties are often useful in reducing the complexity in computing the Fourier-series coefficients.

#### Least-Squares Approximation Property

If we were to construct signal \(x\left(t\right)\) from a set of exponentials, how many terms must we use to obtain a reasonable approximation? If \(x\left(t\right)\) is a band-limited signal, we can use a finite number of exponentials. Otherwise, using only a finite number of terms, say \(M\), results in an approximation of \(x\left(t\right)\). The difference between \(x\left(t\right)\) and its approximation is the error in the approximation. We want the approximation to be "close" to \(x\left(t\right)\) in some sense. For the best approximation, we must minimize some measure of the error. A useful and mathematically tractable criterion we use is the average of the total squared error over one period, also known as the mean-squared value of the error. This criterion of approximation is also known as the approximation of \(x\left(t\right)\) by least squares. The least-squares approximation property of the Fourier series relates quantitatively the energy of the difference signal to the error difference between the specified signal \(x\left(t\right)\) and its truncated Fourier-series approximation. Specifically, it shows that the Fourier-series coefficients are the best choice (in the mean-square sense) for the coefficients of the truncated series.

Now suppose that \(x\left(t\right)\) can be approximated by a truncated series of exponentials in the form

\[x_{N}(t)=\sum_{n=-N}^{N}d_{n}\,\exp\left[jn\omega_{0}t\right] \tag{3.4.1}\]

selecting coefficient \(d_{n}\) in the finite exponential series of Equation (3.4.1) to be identical with the Fourier-series coefficients \(c_{n}\). That is, if the Fourier-series expansion of the signal \(x\left(t\right)\) is truncated at any given value of \(N\), it approximates \(x\left(t\right)\) with smaller mean-square error than any other exponential series with the same number of terms. Furthermore, since the error is the sum of positive terms, the error decreases monotonically as the number of terms used in the approximation increases.

**Example 3.4.1**: Consider the approximation of the periodic signal \(x\left(t\right)\) shown in Figure 3.2.2 by a set of \(2N+1\) exponentials. In order to see how the approximation error varies with the number of terms, we consider the approximation of \(x\left(t\right)\) based on three terms, then seven terms, nine terms, and so on (note that \(x\left(t\right)\) contains only odd harmonics). For \(N=1\) (three terms), the minimum mean-square error is

\[\left(MSE\right)_{\min} =\sum_{l\,n\,l\,>\,1}\,{\left|{c_{n}}\right|}^{2}\] \[=\sum_{l\,n\,l\,>\,1}\,\frac{4K^{2}}{n^{\,2}\,\pi^{2}}\,\sin^{4} \,\frac{n\pi}{2}\] \[=\frac{4K^{2}}{\pi^{2}}\sum_{l\,n\,l\,>\,1\atop n\,\,\text{odd}} \frac{1}{n^{\,2}}\] \[=\frac{8K^{2}}{\pi^{2}}\bigg{(}\,\frac{3\pi^{2}}{24}-1\bigg{)}\] \[\simeq\,0.189K^{2}\]

Similarly, for \(N=3\), it can be shown that

\[\left(\text{MSE}\right)_{\min} =\frac{8K^{2}}{\pi^{2}}\left[\frac{3\pi^{2}}{24}-\frac{10}{9}\right]\] \[\simeq\,0.01K^{2}\]

#### Effects of Symmetry

Unnecessary work (and corresponding sources of errors) in determining Fourier coefficients of periodic signals can be avoided if the signals possess any type of symmetry. The important types of symmetry are

1. even symmetry, \(x(t)=x\left(-t\right)\),
2. odd symmetry, \(x(t)=-x\left(-t\right)\),
3. half-wave odd symmetry, \(x(t)=-x\left(t+\frac{T}{2}\right)\).

These symmetries are illustrated in Figure 3.4.1.

The recognition of the existence of one or more of these symmetries results in the simplification of the computation of the Fourier-series coefficients. For example, the Fourier series of an even signal \(x\left(t\right)\) having period \(T\) is a "Fourier cosine series":

\[x\left(t\right)=a_{0}+\sum\limits_{n=1}^{\infty}\,a_{n}\,\cos\,\frac{2n\pi t}{T}\]

with coefficients

\[a_{0}=\frac{2}{T}\int\limits_{0}^{T/2}\,x\left(t\right)\,dt,\quad\text{ and }\quad\quad a_{n}=\frac{4}{T}\int\limits_{0}^{T/2}\,x\left(t\right)\,\cos\, \frac{2n\pi t}{T}\,\,dt\]

whereas the Fourier series of an odd signal \(x\left(t\right)\) having period \(T\) is a "Fourier sine series":

\[x\left(t\right)=\sum\limits_{n=1}^{\infty}\,b_{n}\,\sin\,\frac{2n\pi t}{T}\]

with coefficients

\[b_{n}=\frac{4}{T}\int\limits_{0}^{T/2}\,x\left(t\right)\,\sin\,\frac{2n\pi t} {T}\,\,dt\]

Figure 3.4.1: Types of symmetry.

The consequence of these symmetries are summarized in Table 3.1.

In Example 3.2.1, \(x\left(t\right)\) is an odd signal and, therefore, \(c_{n}\) are imaginary (\(a_{n}=0\),), whereas \(c_{n}\) in Example 3.2.3 are real (\(b_{n}=0\)) because \(x\left(t\right)\) is an even signal.

**Example 3.4.2**: Consider the signal

\[\ddot{x}\left(t\right)=\begin{cases}A-\dfrac{4A}{T}\ t,\qquad\ \ 0<t<T/2\\ \dfrac{4A}{T}\ t-3A,\qquad\ T/2<t<T\end{cases}\]

Signal \(x\left(t\right)\) is shown in Figure 3.4.2.

Notice that \(x\left(t\right)\) is both an even and half-wave odd signal. Therefore, \(b_{n}=0\) and we expect to have no even harmonics.

\[a_{n} =\dfrac{4}{T}\int\limits_{0}^{T/2}\left(A-\dfrac{4At}{T}\right)\cos \ \dfrac{2n\pi t}{T}\ dt\] \[=\dfrac{4A}{\left(n\pi\right)^{2}}\left(1-\cos\ (n\pi)\right)\]

\begin{table}
\begin{tabular}{l|c|c|c|l} \hline
**Symmetry** & \(a_{0}\) & \(a_{n}\) & \(b_{n}\) & **Remarks** \\ \hline Even & \(a_{0}\neq 0\) & \(a_{n}\neq 0\) & \(b_{n}=0\) & Integrate over T/2 only \\ Odd & \(a_{0}=0\) & \(a_{n}=0\) & \(b_{n}\neq 0\) & Integrate over T/2 only. \\ Half-wave odd & \(a_{0}=0\) & \(a_{2n}=0\) & \(b_{2n}=0\) & Integrate over T/2, \\  & & \(a_{2n+1}\neq 0\) & \(b_{2n+1}\neq 0\) & and multiply the coefficients by 2. \\ \hline \end{tabular}
\end{table}
Table 3.1: Effects of Symmetry

Figure 3.4.2: Signal \(x\left(t\right)\) for Example 3.4.2.

\[=\begin{bmatrix}0,&n&\text{even}\\ \dfrac{8A}{\left(n\pi\right)^{2}},&n&\text{odd}\end{bmatrix}\]

Observe that \(a_{0}\), which corresponds to the dc term (zero harmonic), is zero because the area under one period of \(x\left(t\right)\) evaluates to zero.

#### Linearity

Suppose that \(x\left(t\right)\) and \(y\left(t\right)\) are periodic, both having the same period. Let their Fourier-series expansions be given by

\[x\left(t\right) =\sum_{n\,=\,-\,-\,\infty}^{\infty}\beta_{n}\,\exp\left[\,jm\omega _{0}\,t\right] \tag{3.4.9a}\] \[y\left(t\right) =\sum_{n\,=\,-\,-\,\infty}^{\infty}\gamma_{n}\,\exp\left[\,jm\omega _{0}\,t\right] \tag{3.4.9b}\]

and let

\[z\left(t\right) =k_{1}x\left(t\right)+k_{2}y\left(t\right)\]

where \(k_{1}\) and \(k_{2}\) are arbitrary constants. Then we can write

\[z\left(t\right) =\sum_{n\,=\,-\,\infty}^{\infty}\left(k_{1}\beta_{n}+k_{2}\gamma _{n}\right)\,\exp\left[\,jm\omega_{0}\,t\right]\] \[=\sum_{n\,=\,-\,\infty}^{\infty}\alpha_{n}\,\exp\left[\,jm\omega _{0}\,t\right]\]

The last equation implies that the Fourier coefficients of \(z\left(t\right)\) are

\[\alpha_{n} =k_{1}\beta_{n}+k_{2}\gamma_{n} \tag{3.4.10}\]

#### Product of Two Signals

If \(x\left(t\right)\) and \(y\left(t\right)\) are periodic signals with the same period as in Equation (3.4.9), their product \(z\left(t\right)\) is given by

\[z\left(t\right) =x\left(t\right)y\left(t\right)\] \[=\sum_{n\,=\,-\,\infty}^{\infty}\beta_{n}\,\exp\left[\,jm\omega_{ 0}\,t\right]\,\sum_{m\,=\,-\,\infty}^{\infty}\gamma_{m}\,\exp\left[\,jm\omega _{0}\,t\right]\] \[=\sum_{n\,=\,-\,\infty}^{\infty}\,\sum_{m\,=\,-\,\infty}^{\infty }\beta_{n}\gamma_{m}\,\exp\left[\,j\left(n+m\right)\omega_{0}\,t\right]\] \[=\sum_{l\,=\,-\,\infty}^{\infty}\left(\sum_{m\,=\,-\,\infty}^{ \infty}\beta_{l-m}\gamma_{m}\right)\,\exp\left[\,jl\omega_{0}\,t\right] \tag{3.4.11}\]

#### Parseval's Theorem

In Chapter 1, it was shown that the average power of a periodic signal \(x\left(t\right)\) is given by

\[P=\frac{1}{T}\int\limits_{<T>}\left|x\left(t\right)\right|^{2}\,dt\]

The square root of the average power, called the root-mean-square (or rms) value of \(x\left(t\right)\), is a useful measure of the amplitude of a complicated waveform. For example, the complex exponential signal \(x\left(t\right)=c_{n}\,\exp\left[\,jn\omega_{0}t\right]\) with frequency \(n\omega_{0}\) has \(\left|\,c_{n}\,\right|^{2}\) as its average power. The relationship between the average power of a periodic signal and the power in its harmonics is one form of Parseval's theorem (this form of Parseval's theorem is the conventional one).

If \(x\left(t\right)\) and \(y\left(t\right)\) are periodic signals with the same period \(T\) and Fourier-series coefficients \(\beta_{n}\) and \(\gamma_{n}\), respectively, we have seen that the product of \(x\left(t\right)\) and \(y^{*}\left(t\right)\) has Fourier-series coefficients \(\alpha_{n}\) given by (see Equation (3.4.12))

\[\alpha_{n}=\sum\limits_{m\,=\,-\infty}^{\infty}\beta_{n+m}\gamma_{m}^{*}\]

The dc component, or the full-cycle time average, of the product is

\[\alpha_{0}=\frac{1}{T}\int\limits_{0}^{T}x\left(t\right)y^{*}\left(t\right)\,dt\]

\[=\sum\limits_{m\,=\,-\infty}^{\infty}\beta_{m}\gamma_{m}^{*} \tag{3.4.16}\]

If we let \(y\left(t\right)=x\left(t\right)\) in this expression, then as a consequence, \(\beta_{n}=\gamma_{n}\) and Equation (3.4.16) becomes

\[\frac{1}{T}\int\limits_{<T>}\left|x\left(t\right)\right|^{2}\,dt=\sum\limits_{ m\,=\,-\infty}^{\infty}\left|\,\beta_{m}\,\right|^{2} \tag{3.4.17}\]

The left-hand side is the average power of the periodic signal \(x\left(t\right)\). The result indicates that the total average power of \(x\left(t\right)\) is the sum of the average power in each harmonic component. Even though power is a nonlinear quantity, we can use superposition of average powers in this particular situation, provided all the individual components are harmonically related.

We now have two different ways of finding the average power of any periodic signal \(x\left(t\right)\): in the time domain using the left-hand side of Equation (3.4.17), and in the frequency domain, using the right-hand side of the same equation.

#### Shift in Time

If \(x\left(t\right)\) has the Fourier-series coefficients \(c_{n}\), then the signal \(x\left(t-\tau\right)\) has coefficients \(d_{n}\), where\[d_{n} =\frac{1}{T}\int\limits_{<T>}x(t-\tau)\,\exp\left[\,-jn\omega_{0}\,t \right]\,dt\] \[=\exp\left[\,-j\omega_{0}\,\tau\right]\,\frac{1}{T}\int\limits_{<T> }x(\sigma)\,\exp\left[\,-jn\omega_{0}\sigma\right]\,d\sigma\] \[=c_{n}\exp\left[\,-jn\omega_{0}\,\tau\right] \tag{3.4.18}\]

Thus, if the Fourier-series representation of a periodic signal \(x(t)\) is known relative to one origin, the Fourier series relative to another origin shifted by \(\tau\) is obtained by adding the phase shift \(n\omega_{0}\tau\) to the phase of the Fourier coefficients of \(x(t)\).

Consider the periodic signal shown in Figure 3.4.4. Signal \(x(t)\) can be written as the sum of the two periodic signals \(x_{1}(t)\) and \(x_{2}(t)\), each with period \(2\pi/\omega_{0}\), where \(x_{1}(t)\) is the half-wave rectified signal of Example 3.2.2 and \(x_{2}(t)=x_{1}(t-\pi/\omega_{0})\). Therefore, if \(\beta_{n}\) and \(\gamma_{n}\) are the Fourier coefficients of \(x_{1}(t)\) and \(x_{2}(t)\) respectively, then, according to Equation (3.4.18),

\[\gamma_{n} =\beta_{n}\cdot\exp\left[\,-jn\omega_{0}\,\frac{\pi}{\omega_{0}}\,\right]\] \[=\beta_{n}\,\exp\left[\,-jn\pi\right]=(-1)^{n}\beta_{n}\]

By using Equation (3.4.10), the Fourier-series coefficients of \(x(t)\) are

\[\alpha_{n} =\beta_{n}+(-1)^{n}\beta_{n}\] \[=\left\{\begin{aligned} & 2\beta_{n},& n \text{ is even}\\ & 0,& n\text{ is odd}\end{aligned}\right.\]

where the Fourier-series coefficients of the periodic signal \(x_{1}(t)\) are given in Equation (3.2.16) as

\[\beta_{n}=\frac{\omega_{0}}{2\pi}\int\limits_{0}^{\pi/\omega_{0}}E\,\sin \omega_{0}t\,\exp\left[\,jn\omega_{0}t\right]\,dt\]

Figure 3.4.4: Signal \(x(t)\) for Example 3.4.4.

\[= \left\{\begin{aligned} &\frac{E}{\pi(1-n^{2})},\qquad n\,\,\, \text{even}\\ &\frac{-jnE}{4},\qquad\qquad n\,\,=\pm 1\\ & 0,\qquad\qquad\qquad\text{otherwise}\end{aligned}\right.\]

Thus,

\[\alpha_{n}=\left\{\begin{aligned} &\frac{2E}{\pi(1-n^{2})},\qquad n\,\,\, \text{even}\\ & 0,\qquad\qquad\qquad\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,n\,\, \text{odd}\end{aligned}\right.\]

This result can be verified by directly computing the Fourier-series coefficients of \(x\left(t\right)\).

#### Integration of Periodic Signals

If the periodic signal contains a nonzero average value (\(c_{0}\neq 0\)), then the integration of this signal produces a component that increases linearly with time and, therefore, the resultant signal is nonperiodic. However, if \(c_{0}=0\), then the integrated signal is periodic, but might contain a dc component. Integrating both sides of Equation (3.2.3) yields

\[\int\limits_{-\infty}^{t}x\left(\tau\right)d\tau=\sum\limits_{n\,\,=-\infty}^{ \infty}\frac{c_{n}}{jn\omega_{0}}\,\exp\left[jn\omega_{0}\,t\right],\qquad n\neq 0 \tag{3.4.19}\]

The relative amplitudes of the harmonics of the integrated signal compared with its fundamental are less than those for the original unintegrated signal. In other words, integration attenuates (deemphasizes) the magnitude of the high-frequency components of the signal. High-frequency components of the signal are the main contributors to the sharp details such as those occurring at the points of discontinuity or discontinuous derivatives of the signal. Hence, integration smooths the signal and this is one of the reasons it is sometimes called a smoothing operation.

### Systems with Periodic Inputs

Consider a linear time-invariant continuous-time system with impulse response \(h\left(t\right)\). From Chapter 2, we know that the response \(y\left(t\right)\) resulting from an input \(x\left(t\right)\) is given by

\[y\left(t\right)=\int\limits_{-\infty}^{\infty}h\left(\tau\right)x\left(t-\tau \right)\,d\tau\]

For complex exponential inputs of the form \[x\left(t\right)=\exp\left[\,j\omega t\right]\]

the output of the system is

\[y\left(t\right) =\int\limits_{-\infty}^{\infty}h\left(\tau\right)\exp\left[\,j \omega(t-\tau)\right]\,d\tau\] \[=\exp\left[\,j\omega t\right]\int\limits_{-\infty}^{\infty}h\left( \tau\right)\exp\left[\,-j\omega\tau\right]\,d\tau\]

By defining

\[H\left(\omega\right)=\int\limits_{-\infty}^{\infty}h\left(\tau\right)\exp \left[\,-j\omega\tau\right]\,d\tau \tag{3.5.1}\]

we can write

\[y\left(t\right)=H\left(\omega\right)\exp\left[\,j\omega t\right] \tag{3.5.2}\]

\(H(\omega)\) is called the system (transfer) function and is a constant for fixed \(\omega\). Equation (3.5.2) is of fundamental importance because it tells us that the system response to a complex exponential is also a complex exponential, with the same frequency \(\omega\), scaled by the quantity \(H(\omega)\). The magnitude \(\left|H(\omega)\right|\) is called the magnitude function of the system, and \(\Join H(\omega)\) is known as the phase function of the system. Knowing \(H(\omega)\), we can determine if the system amplifies or attenuates a given sinusoidal component of the input and how much of a phase shift the system adds to that particular sinusoidal component of the input.

To determine the response \(y\left(t\right)\) of a LTI system to a periodic input \(x\left(t\right)\) with the Fourier-series representation of Equation (3.2.3), we use the linearity property and Equation (3.5.2) to obtain

\[y\left(t\right)=\sum\limits_{n\,=\,-\infty}^{\infty}H(n\omega_{0})\,c_{n}\, \exp\left[\,jn\omega_{0}\,t\right] \tag{3.5.3}\]

Equation (3.5.3) tells us that the output signal is the summation of exponentials with coefficients

\[d_{n}=H(n\omega_{0})\,\,c_{n} \tag{3.5.4}\]

These coefficients are the outputs of the system in response to \(c_{n}\exp\left[\,jn\omega_{0}\,t\,\right]\). Note that since \(H(n\omega_{0})\) is a complex constant for each \(n\), it follows that the output is also periodic with Fourier-series coefficients \(d_{n}\). In addition, since the fundamental frequency of \(y\left(t\right)\) is \(\omega_{0}\), which is the fundamental frequency of the input \(x\left(t\right)\), we also have that the period of \(y\left(t\right)\) is equal to the period of \(x\left(t\right)\). Hence, the response of a LTI system to a periodic input with period \(T\) is periodic with the same period.

**Example 3.5.1**: Consider the system described by the following input/output differential equation:

\[y^{\left(n\right)}(t)+\sum\limits_{i\,=\,0}^{n\,-\,1}p_{i}\,\,y^{\left(i \right)}(t)=\sum\limits_{i\,=\,0}^{m}q_{i}\,\,\dot{x}^{\left(i\right)}(t)\]For input \(x(t)=\exp\left[\,J\omega t\right]\), the corresponding output is \(y(t)=H(\omega)\exp\left[\,j\omega t\right]\). Since every input and output should satisfy the system differential equation, substituting in the differential equation yields

\[\left[\,(j\omega)^{n}+\sum_{i=0}^{n-1}p_{i}(j\omega)^{i}\,|H(\omega)\,\exp\left[ j\omega t\right]=\sum_{i=0}^{m}q_{i}(j\omega)^{j}\,\exp\left[j\omega t\right]\]

Solving for \(H(\omega)\), we obtain

\[H(\omega)=\frac{\sum_{i=0}^{m}q_{i}(j\omega)^{i}}{(j\omega)^{n}+\sum_{i=0}^{n- 1}p_{i}(j\omega)^{i}}\,\qed\]

Let us find the output voltage \(y(t)\) of the system shown in Figure 3.5.1 if the input voltage is the periodic signal

\[x(t)=4\cos t-2\cos 2t\]

Applying Kirchhoff's voltage law to the circuit yields

\[\frac{dy(t)}{dt}+\frac{R}{L}y(t)=\frac{R}{L}x(t)\]

If we set \(x(t)=\exp\left[\,j\omega t\right]\) in this equation, the output voltage is \(y(t)=H(\omega)\exp\left[\,j\omega t\right]\). Using the system differential equation, we obtain

\[j\omega H(\omega)\exp\left[\,j\omega t\right]+\frac{R}{L}H(\omega)\,\exp\left[ \,j\omega t\right]=\frac{R}{L}\,\exp\left[\,j\omega t\right]\]

Solving for \(H(\omega)\) yields

\[H(\omega)=\frac{R\,/\,L}{R\,/\,L+j\omega}.\]

Figure 3.5.1: System for Example 3.5.2.

At any frequency \(\omega=n\omega_{0}\), the system function is

\[H\left(n\omega_{0}\right)=\frac{R\ /\ L}{R\ /\ L\ +jn\omega_{0}}.\]

For our case, \(\omega_{0}=1\) and \(R\ /\ L=1\), so that the output is

\[y\left(t\right) =\frac{2}{1\ +j\ 1}\ \exp\left[\ jt\ \right]\ +\frac{2}{1\ -j\ 1}\exp\left[\ -jt\right]-\frac{1}{1\ +j\ 2}\ \exp\left[\ j2t\ \right]-\frac{1}{1\ -j\ 2}\ \exp\left[\ -j2t\ \right]\] \[=\frac{2\sqrt[2]{2}\cos\left(t-45^{\ *}\right)-\frac{2}{\sqrt{5}} \cos\left(2t-63^{\ *}\right)\]

**Example 3.5.3**: Consider the circuit shown in Figure 3.5.2. The differential equation governing the system is

\[i\left(t\right)=C\ \frac{dv\left(t\right)}{dt}+\frac{v\left(t\right)}{R}\]

For an input of the form \(i\left(t\right)\!=\!\exp\left[\ j\omega t\right]\), we expect the output \(v\left(t\right)\) to be \(v\left(t\right)\!=\!H(\omega)\exp\left[\ j\omega t\right]\). Substituting in the differential equation yields

\[\exp\left[\ j\omega t\right]=Cj\omega H(\omega)\ \exp\left[\ j\omega t \right]+\frac{1}{R}\ H(\omega)\ \exp\left[\ j\omega t\right]\]

Canceling the \(\exp\left[\ j\omega t\right]\) term and solving for \(H(\omega)\), we have

\[H(\omega)=\frac{1}{1/R+j\omega C}\]

Let us investigate the response of the system to a more complex input. Consider an input that is given by the periodic signal \(x\left(t\right)\) in Example 3.2.1. The input signal is periodic with period \(2\) and \(\omega_{0}=\pi\), and we have found that

\[c_{n}=\left\{\begin{array}{cc}\frac{2K}{jn\pi},&n\ \ \text{odd}\\ 0,&n\ \ \text{even}\end{array}\right.\]

Equation (3.5.3). Let us investigate the effect of the system on the harmonics of the input signal \(x(t)\). For this reason, assume that \(\omega_{0}=120\pi\), \(LC=1.0\times 10^{-4}\) and \(L\)\(/R=1.0\times 10^{-4}\). For these values, the amplitude and phase of \(H\left(n\omega_{0}\right)\) can be approximated by

\[\left|H(n\omega_{0})\right|=\frac{1}{\left(n\omega_{0}\right)^{2}LC}\]

\[\leqslant H(n\omega_{0})=\frac{1}{n\omega_{0}RC}\]

Note that the amplitude of \(H(n\omega_{0})\) decreases as rapidly as \(1/n^{2}\). The amplitude of the first few components \(d_{n}\), \(n=0\), \(1\), \(2\), \(3\), \(4\), in the Fourier-series representation of \(y\left(t\right)\) are as follows:

\[\left|d_{0}\right|=\frac{E}{\pi},\qquad\left|d_{1}\right|=7.6\times 10^{-2} \ \frac{E}{4},\qquad\left|d_{2}\right|=1.8\times 10^{-2}\frac{E}{3\pi}\]

\[\left|d_{3}\right|=0,\qquad\left|d_{4}\right|=4.4\times 10^{-3}\ \frac{E}{15\pi}\]

The dc component of the input \(x\left(t\right)\) has been passed without any attenuation, whereas the first and higher-order harmonics have suffered reduction in their amplitudes. The reduction increases as the order of the harmonic increases. As a matter of fact, the function of the previous circuit is to attenuate all the ac components of the half-wave rectified signal. Such an operation is known as smoothing or filtering. The ratio of the amplitudes of the first harmonic and the dc component is \(7.6\times 10^{-2}\pi/4\) in comparision with a value of \(\pi/4\) for the unfiltered half-wave rectified waveform. As we mentioned before, complex circuits can be designed to produce better rectified signals. The designer is always faced with the issue of a trade-off between complexity and performance.

We have seen so far that when signal \(x\left(t\right)\) is transmitted through an LTI system (communication system, amplifier, etc.) with transfer function \(H\left(\omega\right)\), the output \(y\left(t\right)\) is, in general, different from \(x\left(t\right)\) (distorted). An LTI system is said to be distortionless if the input and the output have identical signal shapes within a multiplicative constant. A delayed output that retains the input-signal shape is also considered distortionless. Thus, the input/output relationship for a distortionless LTI should satisfy

\[y\left(t\right)=Kx\left(t-t_{d}\right) \tag{3.5.5}\]

This simply means that all input exponential components must undergo the same attenuation or amplification so that

\[\left|H\left(n\omega_{0}\right)\right|=K \tag{3.5.6}\]

Also, all exponential components must experience the same delay \(t_{d}\). For example, for an input \(\exp\left[\left.jn\omega_{0}\right.t\right]\), a delay \(t_{d}\) yields

\[\exp\left[\left.jn\omega_{0}\left(t-t_{d}\right)\right]=\exp\left[\left.jn \omega_{0}t\right]\exp\left[-jn\omega_{0}\right.t_{d}\right]\right.\]This corresponds to phase lag \(n\omega_{0}t_{d}\), which is proportional to the harmonic frequency \(n\omega_{0}\). The ideal amplitude and phase characteristics of an LTI system that is distortionless in the frequency range \(-\omega_{c}\)\(<\)\(\omega\)\(<\)\(\omega_{c}\) is shown in Figure 3.5.4.

**Example 3.5.5**: The input and output of a LTI system are

\[x\left(t\right) =8\exp\left[\left.j(\omega_{0}t+30)\right]+6\exp\left[\left.j(3 \omega_{0}\right.t-15)\right]-2\exp\left[\left.j\left(5\omega_{0}\right.t+45 \right)\right]\] \[y\left(t\right) =4\exp\left[\left.j(\omega_{0}t-15)\right]-3\exp\left[\left.j(3 \omega_{0}\right.t+30)\right]+\exp\left[\left.j\left(5\omega_{0}\right.t) \right]\right.\]

We want to determine by inspection if these two signals have the same shape and to find the impulse response of the system. Notice that the magnitudes of corresponding harmonics all have a common ratio, 2. In regard to phase, in the first harmonic, \(y\left(t\right)\) lags \(x\left(t\right)\) by \(45^{*}\). In the third harmonic, \(y\left(t\right)\) lags \(x\left(t\right)\) by \(135^{*}=3\times\)\(45^{*}\). In the fifth harmonic, \(y\left(t\right)\) lags \(x\left(t\right)\) by \(225^{*}=5\times 45\). Therefore, the two signals have the same shape except for a scale factor of \(1/2\) and phase shift of \(\pi/4\). This phase shift corresponds to a time shift of \(\tau=\pi/4\omega_{0}\). Hence, \(y\left(t\right)\) can be written as

\[y\left(t\right)=\frac{1}{2}\ x\left(t-\frac{\pi}{4\omega_{0}}\right)\]

By inspection, the system impulse response is

\[h\left(t\right)=\frac{1}{2}\ \delta\ (t-\frac{\pi}{4\omega_{0}})\]

This system is distortionless since it causes a periodic input to undergo a change in amplitude and a shift in time to produce the output, but otherwise causes no change in the shape of the output signal.

Let \(x\left(t\right)\) and \(y\left(t\right)\) be the input and the output, respectively, of the simple RC circuit shown in Figure 3.5.5. Applying Kirchhoff's voltage law, we obtain

Figure 3.5.4: Magnitude and phase characteristics of a distortionless system.

\[\frac{dy(t)}{dt}+\frac{1}{RC}\ y(t)=\frac{1}{RC}\ x(t)\]

Setting \(x\left(t\right)=\exp\left[\ j\omega t\right]\) and recognizing that \(y\left(t\right)=H(\omega)\)\(\exp\left[\ j\omega t\right]\), we have

\[j\omega\ H(\omega)\ \exp\left[\ j\omega t\right]+\frac{1}{RC}\ H(\omega)\ \exp\left[\ j\omega t \right]=\frac{1}{RC}\ \exp\left[\ j\omega t\right]\]

Solving for \(H(\omega)\) yields

\[H(\omega)=\frac{1/RC}{1/RC+j\omega}=\frac{\eta}{\eta+j\omega}\]

where

\[\eta=\frac{1}{10^{4}\times 10^{-11}}=10^{7}\ s^{-1}\]

Hence,

\[\left|\ H(\omega)\right|=\frac{\eta}{\sqrt{\eta^{2}+\omega^{2}}}\]

The amplitude and phase spectra of \(H\left(\omega\right)\) are shown in Figure 3.5.6. Note that for \(\omega\ll\eta\),

\[H(\omega)\ \simeq\ 1\]

and

\[\xi\ H(\omega)\simeq-\frac{\omega}{\eta}\]

that is, the magnitude and phase characteristcs are practically ideal. For example, for input

\[x\left(t\right)=A\ \exp\left[\ j10^{3}t\right]\]

the system is practically distortionless with output

Figure 3.5.5: Circuit for Example 3.5.6.

\[y\left(t\right) =H\left(10^{3}\right)A\,\exp\left[\,j10^{3}t\,\right]\] \[=\frac{10^{7}}{10^{7}+j10^{3}}\,\,A\,\exp\left[\,j10^{3}t\,\right]\] \[\simeq\,A\,\,\exp\left[\,j10^{3}(t-10^{-7})\right]\]

Hence, the time delay is \(10^{-7}s\). 

### 3.6 Gibbs Phenomenon

Consider the signal in Example 3.2.1, where we have shown that \(x\left(t\right)\) could be expressed as

\[x\left(t\right)=\frac{2K}{j\pi}\sum_{\begin{subarray}{c}n\,=\,-\infty\\ n\,\,\text{odd}\end{subarray}}^{\infty}\frac{1}{n}\,\exp\left[\,jn\pi t\,\right]\]

We wish to investigate the effect of truncating the infinite series. For this purpose, consider the truncated series

\[x_{N}\left(t\right)=\frac{2K}{j\pi}\sum_{\begin{subarray}{c}n\,=\,-N\\ n\,\,\text{odd}\end{subarray}}^{N}\frac{1}{n}\,\exp\left[\,jn\pi t\,\right]\]

The truncated series is shown in Figure 3.6.1 for \(N\,=\,3\) and \(5\). Note that even with \(N\,=\,3\), \(x_{3}\left(t\right)\) resembles the pulse train in Figure 3.2. Increasing \(N\) to \(39\), we obtain the approximation shown in Figure 3.6.2. It is clear that, except for the overshoot at the points of discontinuity, Figure 3.6.2 is a much closer approximation to the pulse train \(x\left(t\right)\) than \(x_{5}\left(t\right)\). In general, as \(N\) increases, the mean-square error between the approximation and the given signal decreases and the approximation to the given signal improves everywhere except in the immediate vicinity of a finite discontinuity. In the neighborhood of points of discontinuity in \(x\left(t\right)\), the Fourier-series representation fails to

Figure 3.5.6: Magnitude and phase spectra of \(H(\omega)\).

converge even though the mean-square error in the representation approaches zero. Careful examination of the plot in Figure 3.6.2 indicates that the magnitude of the overshoot is approximately 9% higher than signal \(x(t)\). In fact, the 9% overshoot is always present and is independent of the number of terms used to approximate signal \(x(t)\). This observation was first made by mathematical physicist Josiah Willard Gibbs.

To obtain an explanation of this phenomenon, let us consider the general form of a truncated Fourier series:

\[x_{N}(t) =\sum_{n\ =\ -N}^{N}c_{n}\ \exp\left[\,jm\omega_{0}t\right]\] \[=\sum_{n\ =\ -N}^{N}\frac{1}{T}\int\limits_{<T>}x(\tau)\exp\left[\, -jn\omega_{0}\tau\right]\ d\tau\ \exp\left[\,jm\omega_{0}t\right]\] \[=\frac{1}{T}\int\limits_{<T>}x(\tau)\left\{\sum_{n\ =\ -N}^{N}\ \exp\left[\,jn\omega_{0}(t-\tau)\right]\right\}\ d\tau \tag{3.6.1}\]

It can be shown that the sum in braces is equal to (see Problem 3.33)

\[g\left(t-\tau\right)\underline{\Delta}\sum_{n\ =\ -N}^{N}\exp\left[\,jm\omega_{0}(t- \tau)\right]=\frac{\sin\left[(N+\frac{1}{2})\omega_{0}(t-\tau)\right]}{\sin \left(\omega_{0}\frac{t-\tau}{2}\right)} \tag{3.6.2}\]

equation shows that truncating a Fourier series is the same as convolving the given \(x\left(t\right)\) with the signal \(g\left(t\right)\) defined in Equation (3.6.2). The oscillating nature of signal \(g\left(t\right)\) causes the ripples at the points of discontinuity.

Notice that, for any signal, the high-frequency components (high-order harmonics) of its Fourier series are the main contributors to the sharp details such as those occurring at the points of discontinuity or discontinuous derivatives of the signal.

### 3.7 Summary

* A periodic signal \(x\left(t\right)\), of period \(T\), can be expanded in an exponential Fourier series as \[x\left(t\right)=\sum\limits_{n\,=\,-\infty}^{\infty}c_{n}\exp\left[\,\frac{j2n \pi t}{T}\,\right]\]
* The fundamental radian frequency of a periodic signal is related to the fundamental period by \[\omega_{0}=\frac{2\pi}{T}\]
* Coefficients \(c_{n}\) are called the Fourier-series coefficients and are given by \[c_{n}=\frac{1}{T}\int\limits_{<T>}x\left(t\right)\exp\left[-\,\frac{j2n\pi t}{ T}\,\right]\,dt\]* The fundamental frequency \(\omega_{0}\) is also called the first harmonic frequency, the frequency \(2\omega_{0}\) is the second harmonic frequency, and so on.
* The plot of \(\left|c_{n}\right|\) versus \(n\omega_{0}\) is called the magnitude spectrum. The locus of the tips of the magnitude lines is called the envelope of the magnitude spectrum.
* The plot of \(\sphericalangle c_{n}\) versus \(n\omega_{0}\) is called the phase spectrum.
* For periodic signals, both the magnitude and phase spectra are line spectra. The magnitude spectrum has even symmetry, and the phase spectrum has odd symmetry.
* If signal \(x\left(t\right)\) is a real-valued signal, then it can be expanded in a trigonometric series of the form \[x\left(t\right)=a_{0}+\sum\limits_{n\,=\,1}^{\infty}\left(\alpha_{n}\cos\frac{ 2n\pi t}{T}+b_{n}\,\sin\frac{2n\pi t}{T}\right)\]
* The relation between the trigonometric-series coefficients and the exponential-series coefficients is given by \[a_{0} =c_{0}\] \[a_{n} =2\,\text{Re}\left\{c_{n}\right\}\] \[b_{n} =2\,\text{Im}\left\{c_{n}\right\}\] \[c_{n} =\frac{1}{2}\,\left(a_{n}+jb_{n}\right)\]
* An alternative form of the Fourier series is \[x\left(t\right)=A_{0}+\sum\limits_{n\,=\,1}^{\infty}A_{n}\cos\left(\frac{2n \pi t}{T}+\phi_{n}\right)\] with \[A_{0}=c_{0}\] and \[A_{n}=2\,\left|c_{n}\right|\quad\text{ and }\quad\quad\phi_{n}=\sphericalangle c_{n}\]
* For the Fourier series to converge, signal \(x\left(t\right)\) must be absolutely integrable, have only a finite number of maxima and minima, and have a finite number of discontinuities over any period. This set of conditions is known as the Dirichlet conditions.
* If signal \(x\left(t\right)\) has even symmetry, then \[b_{n} =0,\quad\quad n\text{=1,2, }\ldots\] \[a_{0} =\frac{2}{T}\int\limits_{<T/2>}x\left(t\right)\,dt\] \[a_{n} =\frac{4}{T}\int\limits_{<T/2>}x\left(t\right)\cos\frac{2n\pi t}{ T}\,dt\]* If signal \(x(t)\) has odd symmetry, then \[a_{n} =0,\qquad n=0,1,2\,\ldots\] \[b_{n} =\frac{4}{T}\int\limits_{<T/2>}x(t)\sin\frac{2n\pi t}{T}\,dt\]
* If signal \(x(t)\) has half-wave odd symmetry, then \[a_{2n} =0,\qquad n=0,\,1,\,\ldots\] \[a_{2n+1} =\frac{4}{T}\int\limits_{<T/2>}x(t)\cos\frac{2(2n{+}1)\pi t}{T}\,dt\] \[b_{2n} =0,\qquad n=1,\,2,\,\ldots\] \[b_{2n+1} =\frac{4}{T}\int\limits_{<T/2>}x(t)\sin\frac{2(2n{+}1)\pi t}{T}\,dt\]
* If \(\beta_{n}\) and \(\gamma_{n}\) are, respectively, the exponential Fourier-series coefficients for two periodic signals \(x(t)\) and \(y(t)\) with the same period, then the Fourier-series coefficients for \(z\left(t\right)=k_{1}x(t)+k_{2}\,y(t)\) are \[\alpha_{n}=k_{1}\beta_{n}+k_{2}\gamma_{n}\] whereas the Fourier-series coefficients for \(z\left(t\right)=x(t)y\left(t\right)\) are \[\alpha_{n}=\sum\limits_{m=-\infty}^{\infty}\beta_{n-m}\,\gamma_{m}.\]
* For periodic signals with the same period \(T\), the periodic convolution is defined as \[z\left(t\right)=\frac{1}{T}\int\limits_{<T>}x(\tau)\,y(t-\tau)\,d\tau\]
* The Fourier-series coefficients of the periodic convolution of \(x(t)\) and \(y(t)\) are \[\alpha_{n}=\beta_{n}\gamma_{n}\]
* One form of Parseval's theorem states that the energy in signal \(x(t)\) is related to the Fourier-series coefficients \(c_{n}\) as \[E=\sum\limits_{n=-\infty}^{\infty}\,|\,c_{n}\,|^{2}\]
* The system (transfer) function of an LTI system is defined as \[H(\omega)=\int\limits_{-\infty}^{\infty}h(\tau)\exp\left[-j\omega\tau\right] \,d\tau\]
* The magnitude of \(H(\omega)\) is called the magnitude function (characteristic) of the system, and \(\chi H(\omega)\) is known as the phase function (characteristic) of the system.
* Response \(y(t)\) of an LTI system to the periodic input \(x(t)\) is \[y\left(t\right)=\sum_{n\,-\infty}^{\infty}H(n\omega_{0})\,c_{n}\,\exp\left[\,jn \omega_{0}t\right]\] where \(\omega_{0}\) is the fundamental frequency and \(c_{n}\) is the Fourier series coefficients of input \(x\left(t\right)\).
* Representing \(x\left(t\right)\) by a finite series results in an overshoot behavior at the points of discontinuity. The magnitude of the overshoot is approximately 9%. This phenomenon is known as Gibbs phenomenon.

### Checklist of Important Terms

\begin{tabular}{l l} Absolutely integrable signal & Magnitude spectrum \\ Dirichlet conditions & Mean-square error \\ Distortionless system & Minimum mean-square error \\ Even harmonic & Odd harmonic \\ Exponential Fourier series & Parseval's theorem \\ Fourier coefficients & Periodic convolution \\ Gibbs phenomenon & Periodic signals \\ Half-wave odd symmetry & Phase spectrum \\ Laboratory form of Fourier series & Transfer function \\ Least-squares approximation & Trigonometric Fourier series \\ \end{tabular}

### Problems

\begin{tabular}{l l}
3.1. & The exponential Fourier series of a certain periodic signal \(x\left(t\right)\) is given by \\ \[x\left(t\right) = j\exp\left[-j4t\right]-\left(3-j\,3\right)\exp\left[-j3t\, \right]+\left(2+j\,2\right)\exp\left[-j2t\,\right]+\,2\] \[+\,\left(2-j\,2\right)\exp\left[\,j2t\,\right]-\left(3+j\,3\right)\exp \left[\,j3t\,\right]-j\,\exp\left[\,j4t\,\right]\] 1. & Sketch the magnitude and phase spectrum of the two-sided frequency spectrum. 2. & Write \(x\left(t\right)\) in the trigonometric form of the Fourier series. 3.2. & The signal shown in Figure P3.2 is created when a cosine voltage or current waveform is rectified by a single diode, a process known as half-wave rectification. Deduce the exponential Fourier-series expansion for the half-wave rectified signal. 3.3. & Find the trigonometric Fourier-series expansion for the signal in Problem 3.2. & \\
3.4. & The signal shown in Figure P3.4 is created when a sine voltage or current waveform is rectified by a a circuit with two diodes, a process known as full-wave rectification. Deduce the exponential Fourier-series expansion for the full-wave rectified signal. 3.5. & Find the trigonometric Fourier-series expansion for the signal in Problem 3.4. & \\
3.6. & Find the exponential Fourier-series representations of the signals shown in Figure P3.6. & Plot the magnitude and phase spectrum for each case. \\ \end{tabular}